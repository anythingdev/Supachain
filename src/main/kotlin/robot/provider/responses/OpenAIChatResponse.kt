package dev.supachain.robot.provider.responses

import dev.supachain.robot.messenger.messaging.CommonLogProbContainer
import dev.supachain.robot.messenger.messaging.FunctionCall
import dev.supachain.robot.messenger.messaging.Message
import dev.supachain.robot.messenger.messaging.Usage
import dev.supachain.utilities.toJson
import kotlinx.serialization.SerialName
import kotlinx.serialization.Serializable

/**
 * Represents a response from an AI provider in a chat-based interaction.
 *
 * This class encapsulates the data returned by an AI provider after processing a chat request. It provides a
 * structured representation of the provider's output, including potential responses and metadata about the generation process.
 *
 * @property id A unique identifier for this specific response, useful for tracking and referencing.
 * @property type The type of object returned, typically "chat.completion" for chat responses.
 * @property created The Unix timestamp (in seconds) indicating when the response was generated by the provider.
 * @property model The identifier of the language model or system used by the provider to produce the response.
 * @property choices A list of `CommonChatChoice` objects, each representing a potential response from the provider.
 * @property usage A `Usage` object providing details about token usage for the request and response, helpful for cost tracking.
 * @property serviceTier (Optional) The service tier or plan used for the request, if applicable.
 * @property systemFingerprint (Optional) A unique identifier for the system configuration used to generate the response,
 *                             useful for debugging and reproducibility.
 *
 * @since 0.1.0-alpha

 */
@Serializable
data class OpenAIChatResponse(
    val id: String,
    @SerialName("object") val type: String,
    val created: Int,
    val model: String,
    val choices: List<OpenAIChatChoice>,
    val usage: Usage,
    @SerialName("service_tier")
    val serviceTier: String? = null,
    val systemFingerprint: String? = null
) : CommonResponse {
    private var currentChatChoice = 0

    override val rankMessages: List<Message.FromAssistant> get() = choices.map { it.message }
    override val requestedFunctions: List<FunctionCall>
        get() = (rankMessages[0].toolCalls?.filter { it.type == "function" }?.map { it.function } ?: emptyList()) +
                // This is for backwards compatibility of the deprecated OpenAI function call
                listOfNotNull(rankMessages[0].functionCall)
    override fun toString(): String = this.toJson()
}

/**
 * Represents a single choice within a response from an AI provider.
 *
 * This data class encapsulates one possible response generated by an AI provider
 * as part of a larger `CommonResponse`.
 *
 * @property index The position or rank of this choice within the list of choices in the response.
 *                 Lower indices often indicate higher relevance or probability.
 * @property message The actual content of the response, represented as a `Message.FromAssistant` object.
 * @property finishReason A string explaining why the AI provider stopped generating this response. Common reasons
 *                        include reaching a maximum token limit, encountering a stop sequence, or
 *                        completing a natural stopping point in the text.
 * @property logProbability (Optional) A `CommonLogProbContainer` object containing log probabilities for the tokens
 *                          in the generated response. This can be useful for analyzing the model's decision-making process.
 *
 * @since 0.1.0-alpha

 */
@Serializable
data class OpenAIChatChoice(
    val index: Int,
    val message: Message.FromAssistant,
    @SerialName("finish_reason")
    private val finishReason: String,
    @SerialName("logprobs")
    val logProbability: CommonLogProbContainer? = null,
) {
    override fun toString(): String = this.toJson()
}